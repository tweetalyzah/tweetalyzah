{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "consumer_key = 'SsKyv8MtRWadyZNYgVjbXayKl'\n",
    "consumer_secret = 'Phj7VLLb5axFbb4vFrQaY8zbQ93CGuuNHmhhm9idpdNm3dxvma'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "access_token = '714744413117874177-EBk1jFqVDsk7at8UcoMNXvx8XwxEeXx'\n",
    "access_token_secret = 'gHZv6ih1ukeWVlaxcmbcQYiekVZsHb4OxbMOqmWF6ICkx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend Python Engineer en Barcelona https://t.co/qjRFeEhg4O\n",
      "GOAI: Open GPU-Accelerated Data Analytics: https://t.co/Mq4R29EK0K #python\n",
      "I want another ball python (mostly pastel and any morph), a boa, and a crocodile skink in the future ughhhh love reptiles\n",
      "esperando minha bota de python\n",
      "RT @ygaudry: #IoT Projects #Coding Languages\n",
      "1 #Java 2 #C 3 #Javascript 4 #Python 5 #CPlusPlus 6 #Nodejs EclipseFdnâ€¦ https://t.co/b8KMZOvGRC\n",
      "#PhilandoCastile\n",
      "#KohLanta\n",
      "#Ø¨Ø±_Ø§Ù„Ø²ÙˆØ¬_Ø§Ø¹Ø¸Ù…_Ù…Ù†_Ø¨Ø±_Ø§Ù„ÙˆØ§Ù„Ø¯ÙŠÙ†\n",
      "#Ù…ÙˆØ§Ù…Ø±Ù‡_Ù‚Ø·Ø±_Ø¹_Ø§Ù„Ø¨Ø­Ø±ÙŠÙ†\n",
      "Cuba\n",
      "#Ø§Ø±Ø¨Ø­_iphone7_Ù…Ø¹_Ø§Ù„Ø¹Ø¨Ø¯Ø§Ù„Ù„Ø·ÙŠÙ9\n",
      "Fultz\n",
      "John G. Avildsen\n",
      "La Cabrera\n",
      "USS Fitzgerald\n",
      "HojeEuVouFicarLoucoNoYoutube\n",
      "Temuco\n",
      "Romero Gamarra\n",
      "Danny Ainge\n",
      "Nelson ArÃ©valo\n",
      "#MafiaSdvSextouEeu\n",
      "#fi12\n",
      "#17HaziranDÃ¼nyaYalnÄ±zlarGÃ¼nÃ¼\n",
      "#THANKYOUREIGN\n",
      "#DragRaceReunited\n",
      "#CorteDeLuz\n",
      "#GrietaCaliente\n",
      "#ShakespeareanFilmTitles\n",
      "#ElSueldoNoAlcanzaNiPara\n",
      "#AncudSeHacenRealidad\n",
      "#DuranteElTemporalSigoaQuien\n",
      "#BTSINEUROPE\n",
      "#NationalMascotDay\n",
      "#YoApoyoAmancioOrtega\n",
      "#Ù…Ø³Ø§Ø¨Ù‚Ù‡_Ø§Ù„ÙˆÙ„ÙŠØ¯_Ø´ÙØ§Ù‡_Ø§Ù„Ù„Ù‡_21\n",
      "#ØªØ³Ø¬ÙŠÙ„Ø§Øª_Ø­Ù…Ø¯_Ø§Ù„Ø¹Ø·ÙŠÙ‡\n",
      "#NinjaWarrior2\n",
      "#YDeTiMeGusta\n",
      "#VTEP\n",
      "#Ù…Ø³Ø§Ø¨Ù‚Ù‡_Ø¯Ø±Ø¹Ù‡_Ø§Ù„Ø±Ù…Ø¶Ø§Ù†ÙŠÙ‡21\n",
      "#ElViernesSoloSirvePara\n",
      "#KuranHayattÄ±r\n",
      "#SiMiPapÃ¡TuvieraTwitter\n",
      "#DJMABELENMTVHITS\n",
      "#QueensBirthdayHonours\n",
      "#Ø¨Ø±ÙˆÙ†Ùˆ_Ø®Ø·_Ø§Ø­Ù…Ø±\n",
      "#CuicaMILF\n",
      "#Ø¯Ø§Ø±_Ø§Ù„Ø§Ø±ÙƒØ§Ù†_Ø¹Ø²Ù„_Ù…Ø¬Ù„Ø³_Ø§Ù„Ø§Ø¯Ø§Ø±Ù‡\n",
      "#TheLastLeg\n",
      "#Ø¹ÙŠØ¯ÙŠØªÙƒ_Ø±ØºØ¯_Ù…Ø­Ù…Ø¯\n",
      "#JusticeForGrenfell\n",
      "#CallCongressBecause\n",
      "#Ù„Ù‡Ø°Ø§_Ù†Ø¯Ø§ÙØ¹_Ø¹Ù†_Ø§Ù„Ø­Ù‚ÙˆÙ‚\n",
      "#EnUnBarYo\n",
      "#OLHONUMTVHITS\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "twitter_api = tweepy.API(auth)\n",
    "\n",
    "# Search stuff\n",
    "search_results = tweepy.Cursor(twitter_api.search, q = \"Python\").items(5)\n",
    "for result in search_results:\n",
    "    print(result.text)\n",
    "\n",
    "trends = twitter_api.trends_place(1)\n",
    "\n",
    "for trend in trends[0][\"trends\"]:\n",
    "    print(trend['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @BoomCassiopeia: à¸žà¸µà¹ˆà¸£à¸±à¸šà¹„à¸¡à¹ˆà¹„à¸”à¹‰à¸­à¸° à¸žà¸µà¹ˆà¸ªà¸‡à¸ªà¸²à¸£à¸ˆà¸‡à¸®à¸¢à¸­à¸™.. #PRODUCE101FINAL 11700 Thai\n",
      "RT @GraceFVictory: Incase you wondered what fat phobia and thin privilege looks like. ðŸ¤·ðŸ½â€â™€ï¸ðŸ™„ https://t.co/obmr6RbVoI 59363 English\n",
      "RT @S_C_: Wait . Slick fucking Rick . Pimp C and bun . Wow . I just realized how many fresh people the culture has . Big Sean . Sauce moneyâ€¦ 16718 English\n",
      "['Korean', 'English', 'English', 'Arabic', 'Portuguese', 'Spanish', 'Japanese', 'Arabic', 'English', 'English', 'English', 'Japanese', 'English', 'English', 'English', 'Turkish', 'Korean', 'Arabic', 'Japanese', 'Japanese', 'English', 'Thai', 'Korean', 'Thai', 'Turkish', 'Arabic', 'Thai', 'Korean', 'Portuguese', 'Japanese', 'Arabic', 'Japanese', 'Japanese', 'Japanese', 'English', 'Spanish', 'Spanish', 'Arabic', 'Arabic', 'English', 'Portuguese', 'Spanish', 'Japanese', 'Arabic', 'Arabic', 'Japanese', 'Portuguese', 'Spanish', 'Portuguese', 'English', 'Portuguese', 'Arabic', 'Spanish', 'Arabic', 'Portuguese', 'Arabic', 'English', 'English', 'English', 'English', 'Filipino', 'Japanese', 'Urdu', 'Arabic', 'Japanese', 'Thai', 'English', 'Estonian', 'English', 'English', 'English', 'Japanese', 'Arabic', 'English', 'Spanish', 'Arabic', 'English', 'English', 'English', 'Portuguese', 'Turkish', 'Spanish', 'Spanish', 'Hindi', 'Arabic', 'English', 'Portuguese', 'Portuguese', 'Arabic', 'Arabic', 'Arabic', 'Arabic', 'English', 'German', 'English', 'Portuguese', 'English', 'Turkish', 'Arabic', 'English']\n",
      "['Thai', 'English', 'English']\n",
      "Counter({'English': 29, 'Arabic': 21, 'Japanese': 13, 'Portuguese': 11, 'Spanish': 9, 'Korean': 4, 'Turkish': 4, 'Thai': 4, 'Filipino': 1, 'Urdu': 1, 'Estonian': 1, 'Hindi': 1, 'German': 1})\n",
      "Counter({'English': 2, 'Thai': 1})\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import Stream\n",
    "import json\n",
    "from collections import Counter\n",
    " \n",
    "langs = {'ar': 'Arabic', 'bg': 'Bulgarian', 'ca': 'Catalan', 'cs': 'Czech', 'da': 'Danish', 'de': 'German', 'el': 'Greek', 'en': 'English', 'es': 'Spanish', 'et': 'Estonian',\n",
    "         'fa': 'Persian', 'fi': 'Finnish', 'fr': 'French', 'hi': 'Hindi', 'hr': 'Croatian', 'hu': 'Hungarian', 'id': 'Indonesian', 'is': 'Icelandic', 'it': 'Italian', 'iw': 'Hebrew',\n",
    "         'ja': 'Japanese', 'ko': 'Korean', 'lt': 'Lithuanian', 'lv': 'Latvian', 'ms': 'Malay', 'nl': 'Dutch', 'no': 'Norwegian', 'pl': 'Polish', 'pt': 'Portuguese', 'ro': 'Romanian',\n",
    "         'ru': 'Russian', 'sk': 'Slovak', 'sl': 'Slovenian', 'sr': 'Serbian', 'sv': 'Swedish', 'th': 'Thai', 'tl': 'Filipino', 'tr': 'Turkish', 'uk': 'Ukrainian', 'ur': 'Urdu',\n",
    "         'vi': 'Vietnamese', 'zh_CN': 'Chinese (simplified)', 'zh_TW': 'Chinese (traditional)'\n",
    "        }\n",
    " \n",
    " \n",
    "class twitter_listener(StreamListener):\n",
    " \n",
    "    def __init__(self, num_tweets_to_grab, retweet_count=10000):\n",
    "        self.counter = 0\n",
    "        self.num_tweets_to_grab = num_tweets_to_grab\n",
    "        self.retweet_count = retweet_count\n",
    "        self.languages = []\n",
    "        self.top_languages = []\n",
    " \n",
    "    def on_data(self, data):\n",
    "        try:\n",
    "            json_data = json.loads(data)\n",
    "            self.languages.append(langs[json_data[\"lang\"]])\n",
    " \n",
    "            self.counter += 1\n",
    "            retweet_count = json_data[\"retweeted_status\"][\"retweet_count\"]\n",
    " \n",
    "            if retweet_count >= self.retweet_count:\n",
    "                print(json_data[\"text\"], retweet_count, langs[json_data[\"lang\"]])\n",
    "                self.top_languages.append(langs[json_data[\"lang\"]])\n",
    " \n",
    "            if self.counter >= self.num_tweets_to_grab:\n",
    "                print(self.languages)\n",
    "                print(self.top_languages)\n",
    "                print(Counter(self.languages))\n",
    "                print(Counter(self.top_languages))\n",
    "                return False\n",
    " \n",
    "            return True\n",
    "        except:\n",
    "            # @TODO: Very dangerous, come back to this!\n",
    "            pass\n",
    " \n",
    "    def on_error(self, status):\n",
    "        print(status)\n",
    "\n",
    "twitter_stream = Stream(auth, twitter_listener(100))\n",
    "try:\n",
    "    twitter_stream.sample()\n",
    "except Exception as e:\n",
    "    print(e.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:twitter]",
   "language": "python",
   "name": "conda-env-twitter-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
